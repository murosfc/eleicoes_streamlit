# -*- coding: utf-8 -*-
"""Eleicao - Felipe Muros

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TF1ogUKFKIPo4Mavj9F1RGzHh5n7Q-Ub

# Etapa 1: Importação das bibliotecas
"""

# Imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.metrics import accuracy_score

#rede neural
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import LSTM
from keras.layers import Embedding, SpatialDropout1D
from keras.callbacks import ModelCheckpoint

"""# Etapa 2: Carregamento e exploração da base de dados

## Ler base da dados
"""

from google.colab import drive
drive.mount('/content/drive')

candidatos = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Eleicoes/consulta_cand_2020_RJ.csv',sep=';',encoding = "ISO-8859-1")
receitas = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Eleicoes/receitas_candidatos_2020_RJ.csv',sep=';',encoding = "ISO-8859-1")
despesas = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Eleicoes/despesas_contratadas_candidatos_2020_RJ.csv',sep=';',encoding = "ISO-8859-1")

candidatos

receitas

despesas

candidatos.columns

#deletar colunas
candidatos = candidatos.drop(['DT_GERACAO', 'HH_GERACAO', 'ANO_ELEICAO', 'CD_TIPO_ELEICAO',
       'NM_TIPO_ELEICAO', 'NR_TURNO', 'CD_ELEICAO', 'DS_ELEICAO', 'DT_ELEICAO',
       'TP_ABRANGENCIA', 'SG_UF', 'SQ_CANDIDATO', 'NM_URNA_CANDIDATO',
       'NM_SOCIAL_CANDIDATO', 'CD_SITUACAO_CANDIDATURA', 'DS_SITUACAO_CANDIDATURA',
       'CD_DETALHE_SITUACAO_CAND', 'DS_DETALHE_SITUACAO_CAND', 'SG_PARTIDO', 'SQ_COLIGACAO',
       'NM_COLIGACAO', 'DS_NACIONALIDADE', 'SG_UF_NASCIMENTO', 'CD_MUNICIPIO_NASCIMENTO',
       'NM_MUNICIPIO_NASCIMENTO', 'DT_NASCIMENTO', 'NR_TITULO_ELEITORAL_CANDIDATO', 'CD_GENERO',
       'CD_GRAU_INSTRUCAO', 'CD_ESTADO_CIVIL',
       'CD_COR_RACA', 'CD_OCUPACAO',
       'VR_DESPESA_MAX_CAMPANHA', 'CD_SIT_TOT_TURNO',
       'ST_REELEICAO', 'ST_DECLARAR_BENS',
       'NR_PROTOCOLO_CANDIDATURA', 'NR_PROCESSO',
       'CD_SITUACAO_CANDIDATO_PLEITO', 'DS_SITUACAO_CANDIDATO_PLEITO',
       'CD_SITUACAO_CANDIDATO_URNA', 'DS_SITUACAO_CANDIDATO_URNA',
       'ST_CANDIDATO_INSERIDO_URNA'], axis=1)

candidatos.columns

"""##Carregar apenas os dados do Municipio pelo Cargo

###Criação variavel para cargo e Municipio
"""

cargo = 13
municipio = 'CAMPOS DOS GOYTACAZES'

"""Criar Dataframe com somente Candidatos de Campos"""

df_canditado_mun = candidatos.drop(candidatos[candidatos.NM_UE != municipio].index) # Canditados de Campos 
df_canditado_mun = df_canditado_mun.drop(df_canditado_mun[df_canditado_mun.CD_CARGO != cargo].index) # Canditados a vereador
df_canditado_mun.head()

df_canditado_mun['DS_GRAU_INSTRUCAO'].unique()

df_receita_mun = receitas.drop(receitas[receitas.NM_UE != municipio].index)# receitas de Canditados de Campos
df_receita_mun = df_receita_mun.drop(df_receita_mun[df_receita_mun.CD_CARGO != cargo].index)# receitas de Canditados a Vereador
df_receita_mun

df_despesa_mun = despesas.drop(despesas[despesas.NM_UE != municipio].index)# Despess de Canditados de Campos
df_despesa_mun = df_despesa_mun.drop(df_despesa_mun[df_despesa_mun.CD_CARGO != cargo].index)# Despess de Canditados a Vereador
df_despesa_mun

"""## Determinar o valor total que cada Candidato  de receita e despesa contratada"""

df_receita_mun['VR_RECEITA'] = df_receita_mun['VR_RECEITA'].apply(lambda x: float(x.split()[0].replace(',', '.')))
df_despesa_mun['VR_DESPESA_CONTRATADA'] = df_despesa_mun['VR_DESPESA_CONTRATADA'].apply(lambda x: float(x.split()[0].replace(',', '.')))

soma_cand_receita = df_receita_mun.groupby('NR_CPF_CANDIDATO')['VR_RECEITA'].sum().to_frame()  #total receita por Candidato
soma_cand_receita

soma_cand_despesa = df_despesa_mun.groupby('NR_CPF_CANDIDATO')['VR_DESPESA_CONTRATADA'].sum().to_frame() 
soma_cand_despesa

#cria um dataFrame com a juncao de todos os dados
df_valores = soma_cand_receita.merge(soma_cand_despesa, on='NR_CPF_CANDIDATO', how='left')
df = df_canditado_mun.merge(df_valores, on='NR_CPF_CANDIDATO', how='left') 
df

"""# Análise e exploração dos dados"""

#nota-se que alguns candidatos não declaram receita nem despesa, colocaremos estes valores como zero
df.isnull().sum()

df = df.fillna(0)
df.isnull().sum()

#hitograma de idade
plt.hist(x = df['NR_IDADE_DATA_POSSE']);

#pizza genero
genero = df['DS_GENERO'].unique()
data = []

for i in range(len(genero)):
  count = sum(df.DS_GENERO == genero[i])
  data.append(count)

fig, axl = plt.subplots(figsize =(10, 7)) 
axl.pie(data, labels=genero, autopct='%1.1f%%') 
plt.show()

#hitograma despesas
plt.hist(x = df['VR_DESPESA_CONTRATADA']);

#hitograma receitas
plt.hist(x = df['VR_RECEITA']);

#pizza raça
raca = df['DS_COR_RACA'].unique()
data = []
explode = []

for i in range(len(raca)):
  count = sum(df.DS_COR_RACA == raca[i])
  data.append(count)
  explode.append(0.1)

fig, axl = plt.subplots(figsize =(10, 7)) 
axl.pie(data, explode = explode, labels=raca, autopct='%1.1f%%') 
axl.legend(title='Raças', loc='center right', bbox_to_anchor=(1,0,0.5,1))
plt.show()

#treemap dos partidos
grafico = px.treemap(df, path=['DS_COMPOSICAO_COLIGACAO'])
grafico.show()

#treemap doescolaridade
grafico = px.treemap(df, path=['DS_GRAU_INSTRUCAO'])
grafico.show()

"""# Tratamento dos dados"""

df.info()

"""Os dados informados no enunciado para uso na previsão são:
Idade,
Sexo,
Valor de Despesa,
Valor de receita,
Raça,
Partido,
Escolaridade.

Assim os demais serão excluídos 
"""

new_df = df.drop(['SG_UE', 'NM_UE',  'CD_CARGO', 'DS_CARGO', 'NM_CANDIDATO', 'NR_CPF_CANDIDATO','NR_CANDIDATO',
                  'NM_EMAIL', 'TP_AGREMIACAO', 'NR_PARTIDO', 'DS_COMPOSICAO_COLIGACAO', 'CD_NACIONALIDADE', 'DS_ESTADO_CIVIL', 'DS_OCUPACAO'], axis=1)

new_df.info()

"""## LabelEncoder

Aplicaremos o Label Encoder para converter os objetos em dados numéricos
"""

# Função para aplicar o label encoder a cada coluna do tipo object
def transform(feature):
    le = LabelEncoder()
    new_df[feature]=le.fit_transform(new_df[feature])

#separar o label das colunas cujo tipo é object 
col_obj=new_df.select_dtypes(include='object')
col_obj.columns

#Aplicar a função de Label Encoder para cada coluna com itens tipo object
for col in col_obj.columns:
    transform(col)

new_df

"""# Divisão entre previsores e classe"""

# Coluna que contém o resultado da eleição para cada candidato
y = new_df['DS_SIT_TOT_TURNO']
y

#retirando a coluna com os dados de y para atribuir o novo dataframe a X
x_df = new_df.drop(['DS_SIT_TOT_TURNO'],axis=1)
X = x_df

"""# Divisão das bases em treinamento e teste"""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=101)
X_train

scalerTrain = MinMaxScaler(feature_range = (0, 1))
scalerTest = MinMaxScaler(feature_range = (0, 1))
X_train = scalerTrain.fit_transform(X_train)
X_test = scalerTest.fit_transform(X_test)

X_train

X_test

"""# Construção e treinamento RNA (MLP)"""

from sklearn.neural_network import MLPClassifier
modelo = MLPClassifier(verbose = True, hidden_layer_sizes=(14,14), max_iter = 10000)
modelo.fit(X_train, y_train)

"""## Previsões"""

previsoes = modelo.predict(X_test)
previsoes

print("Acurácia = {:.2f}".format(accuracy_score(y_test, previsoes)*100),"%")

#simulando os dados de um novo canditado para testes
# NM_PARTIDO,	NR_IDADE_DATA_POSSE,	DS_GENERO,	DS_GRAU_INSTRUCAO,	DS_COR_RACA,	VR_RECEITA,	VR_DESPESA_CONTRATADA
canditado_novo = np.array([[5, 39, 1, 2, 2, 10000, 100000]]).reshape(-1,1)

#normalizando os dados
scaler = MinMaxScaler(feature_range = (0, 1))
canditado_novo = scaler.fit_transform(canditado_novo)
canditado_novo = canditado_novo.reshape(1,7)

status = {0:'#NULO#', 1:'ELEITO POR MÉDIA', 2:'ELEITO POR QP', 3:'NÃO ELEITO', 4:'SUPLENTE'}
situacao = modelo.predict(canditado_novo)
print("O status do canditado é:" ,status[int(situacao)])

X_test.shape

"""# Construção e treinamento do modelo LSTM"""

#adequando o shape de X para compatibilidade com o LSTM
X_train = X_train.reshape(-1, 1, 7)
X_test  = X_test.reshape(-1, 1, 7)

#criando o modelo com 1 camada de entrada, mais 2 camadas profundas e uma camada de saída. Dropout de 0.2
neuronios = 7
model = Sequential()
model.add(LSTM(units = neuronios, return_sequences = True, input_shape = (1, 7)))
model.add(Dropout(0.2))
model.add(LSTM(units = neuronios, return_sequences = True))
model.add(Dropout(0.2))
model.add(LSTM(units = neuronios))
model.add(Dropout(0.2))
model.add(Dense(units = 1))
model.compile(loss = 'mean_squared_error', optimizer='adam',metrics = ['accuracy'])
print(model.summary())

# Define o checkpoint para recuperar o treinamento, se necessário
filepath = "/content/drive/MyDrive/Colab Notebooks/Eleicoes/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')
callbacks_list = [checkpoint]

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Treinamento da rede neural 
# model.fit(X_train, y_train, epochs = 10, batch_size = 64, callbacks = callbacks_list)

# Resultados da rede neural LTSM
score,acc = model.evaluate(X_test, y_test, verbose = 1, batch_size = 64)
print("score: %.2f" % (score))
print("acc: %.2f" % (acc))

"""## Previsões"""

trainPredict = model.predict(X_train)
testPredict = model.predict(X_test)
trainPredict

# Inverte as previsões por conta da normalização
trainPredict = scaler.inverse_transform(trainPredict)
trainY = scaler.inverse_transform([y_train])
testPredict = scaler.inverse_transform(testPredict)
testY = scaler.inverse_transform([y_test])
trainPredict

"""## Calcula o RMSE"""

import math
from sklearn.metrics import mean_squared_error

trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))
print('Score em Treino: %.2f RMSE' % (trainScore))
testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))
print('Score em Teste: %.2f RMSE' % (testScore))